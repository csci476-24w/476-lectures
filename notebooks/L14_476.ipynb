{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3109b7e-0092-47a3-aca2-288e745731ba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Lecture 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0357b50-2962-423e-85f1-80217ec3d134",
   "metadata": {},
   "source": [
    "#### Announcements\n",
    "* Anyone not paired up yet for P3?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38efd636-c09e-4d1f-a828-33e0fcc75686",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Goals\n",
    "* Know what is meant by a homogeneous \"point at infinity\"\n",
    "* Understand the derivation and significance of:\n",
    "  * The Epipolar plane, epipolar lines, epipoles\n",
    "  * The essential matrix and the fundamental matrix\n",
    "* Be able to set up and solve the reprojection error equations for the Direct Linear Transform (DLT) to find:\n",
    "  * (pose estimation) a camera matrix, given some 3D points and their 2D observations, or\n",
    "  * (triangulation) a 3D point given some camera locations and its 2D observation in each.\n",
    "* Get a general sense of how structure-from-motion can bootstrap both camera geometry and 3D point locations starting only with 2D point correspondences among multiple cameras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef30e2c7-ba6f-48fa-a5ae-bc02d9f73679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# boilerplate setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.abspath(\"../src\")\n",
    "if (src_path not in sys.path):\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Library imports\n",
    "import numpy as np\n",
    "import imageio.v3 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage as skim\n",
    "import cv2\n",
    "\n",
    "# codebase imports\n",
    "import util\n",
    "import filtering\n",
    "import features\n",
    "import geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3e7b96-c6b3-4a78-a8c4-c4e13e8b93cc",
   "metadata": {},
   "source": [
    "### Plan\n",
    "\n",
    "* Points at infinity: intuition\n",
    "  * Intersection point of parallel lines\n",
    "  * Also can be viewed as \"direction vectors\"\n",
    "    * This is nice because if you transform them, the translation gets ignored as you'd want it to when transforming a direction.\n",
    "* Epipolar geometry (via notes): essential and fundamental matrices\n",
    "* Finding the fundamental matrix from 2D correspondences\n",
    "  * 8-point algorithm \n",
    "* Find $R$, $t$ from $E$\n",
    "* Multi-view geometry: problem taxonomy\n",
    "* Multi-view geometry - simplest approach via DLT\n",
    "  * Write down \"reprojection error\" residuals\n",
    "    * Formulate pose estimation problem\n",
    "    * Formulate triangulation problem\n",
    "* Structure from motion: you don't know nothin'!\n",
    "* We can solve for $F$ using 2D correspondences.\n",
    "* Separating E into [R, t]\n",
    "  * What if you know F but not E?\n",
    "    * Trickier\n",
    "* In practice: structure from motion\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bab54f5-afc6-4cd3-8ffd-07d1a01b69a6",
   "metadata": {},
   "source": [
    "Points at infinity: notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240e7e78-63ae-4fea-8ba7-2474c25680de",
   "metadata": {},
   "source": [
    "Epipolar geometry: notes (see also mostly-typed notes linked from course webpage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67f812f-7a5c-4629-ba12-4140bb1463ab",
   "metadata": {},
   "source": [
    "##### HW #1-2: Epipolar geometry of a **rectified** stereo pair\n",
    "\n",
    "1. Given a **rectified stereo pair**, what constraint can you put on the homogeneous coordinates of all epipolar lines $\\ell_p = [a, b, c]$?\n",
    "\n",
    "2. In a **rectified stereo pair**, give the homogeneous coordinates of the right epipole (expressed in the right camera's image coordinates)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767d05db-6bc3-469f-995d-d93f2761250a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Finding the Fundamental Matrix from 2D Correspondences\n",
    "via the **8-point algorithm**\n",
    "\n",
    "Let $p$ and $p'$ be a pair of corresponding points:\n",
    "$$p = (u, v, 1)$$\n",
    "\n",
    "$$p' = (u', v', 1)$$\n",
    "\n",
    "and the fundamental matrix relating their two cameras:\n",
    "\n",
    "$$\n",
    "F = \\begin{bmatrix}\n",
    "f_{11} & f_{12} & f_{13}\\\\\n",
    "f_{21} & f_{22} & f_{23} \\\\\n",
    "f_{31} & f_{32} & f_{33} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The epipolar constraint gives us the constraint:\n",
    "\n",
    "$$\n",
    "p'^T F p = 0\n",
    "$$\n",
    "\n",
    "If we write this out in scalar form, this yields a single equation that's not linear in the point locations, but is linear in the fundamental matrix entries:\n",
    "\n",
    "$$ \n",
    "uu' f_{11} + vu' f_{12} + u'f_{13} + uv' f_{21} + vv'f_{22} + v'f_{23} + uf_{31} + vf_{32} + f_{33} = 0\n",
    "$$\n",
    "\n",
    "Stack eight of these into a homogeneous linear system and you can solve for the entries of $F$ similarly to the way we did it for a homography.\n",
    "\n",
    "**If you're actually going to do this, beware**: the magnitudes of the single terms (e.g., $vf_{32}$) vs the product terms (e.g., $uv' f_{21}$) will differ greatly, causing numerical stability problems. **Fix**: scale all observations to within the range [0,1] so their products can't get crazy; this is the *normalized* 8-point algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c621c94-8bcd-4141-b241-2ea3f5ce70a3",
   "metadata": {},
   "source": [
    "#### Given $F$, can we find $K$ and $[R|t]$?\n",
    "\n",
    "Sort of. You can get $[R|t]$ from $E$ using some SVD tricks.\n",
    "\n",
    "You can get $K$ from $F$ in specialized circumstances but not unambiguously and not in general.\n",
    "\n",
    "In practice: estimate $f$ from camera metadata to get initial estimate, refine using nonlinear optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0969c06a-5f9e-43c3-a965-9a56aef85f6e",
   "metadata": {},
   "source": [
    "#### Multi-view geometry: problem taxonomy\n",
    "Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25d249e-1b6a-43dc-883b-75282bcac5c7",
   "metadata": {},
   "source": [
    "Multi-view geometry - a taxonomy of problems: notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7035ca-1a09-420b-9059-3df0b08683ca",
   "metadata": {},
   "source": [
    "#### Pose Estimation and Triangulation via the Direct Linear Transform (DLT)\n",
    "\n",
    "##### HW Problems 3-7\n",
    "\n",
    "The projection of a 3D point to its 2D coordinates can be written as:\n",
    "$$\n",
    "\\begin{bmatrix}x_i\\\\ y_i \\\\ 1\\end{bmatrix}\n",
    "= \\begin{bmatrix}x_p/w_p\\\\ y_p/w_p \\\\ 1\\end{bmatrix}\n",
    "\\sim\n",
    "\\begin{bmatrix}x_p\\\\ y_p \\\\ w_p\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "p_{00} & p_{01} & p_{02} & p_{03} \\\\ \n",
    "p_{10} & p_{11} & p_{12} & p_{13} \\\\ \n",
    "p_{20} & p_{21} & p_{22} & p_{23} \\\\ \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}X_i\\\\ Y_i \\\\ Z_i \\\\ W_i \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "3. Write down the residuals for the *reprojection error* given a camera matrix $P$, a 3D world point $p_{world}=(X_i, Y_i, Z_i, W_i)$, and its image space coordinates $p_{img} = (x_j, y_j)$. Note that we'll need to use the same \"multiply by the denominator\" trick we used when solving for Homographies, meaning these residuals don't perfectly correspond to the reprojection error.\n",
    "\n",
    "\n",
    "4. Give the first two rows of the $A$ matrix in the least squares system $Ax = 0$ that you'd solve to find the elements of the camera matrix\n",
    "   $$\n",
    "   P = \\begin{bmatrix}\n",
    "   p_{00} & p_{01} & p_{02} & p_{03} \\\\ \n",
    "   p_{10} & p_{11} & p_{12} & p_{13} \\\\ \n",
    "   p_{20} & p_{21} & p_{22} & p_{23} \\\\ \n",
    "   \\end{bmatrix}.\n",
    "   $$\n",
    "   given a (known) set of $n$ 3D points $\\{(X_i, Y_i, Z_i, 1) : 0 < i < n\\}$ and their (known) corresponding 2D projections $\\{(x_i, y_i) : 0 < i < n\\}$. Note that we'll assume here that the 3D points are normalized, *i.e*., $W_i=1$.\n",
    "\n",
    "5. How many 3D-2D point correspondences do you need to compute the entries of $P$?\n",
    "\n",
    "6. Give the first two rows of the $A$ matrix in the least squares system $Ax = 0$ that you'd solve to find the location of a 3D point $[X, Y, Z, W]$ given a set of $m$ camera matrices $P_{1\\ldots m}$ and corresponding observed 2D locations  $\\{(x_i, y_i) : 0 < i < m\\}$. Note here that we're not assuming $W = 1$; this is not requried, but should help with numerical stability.\n",
    "\n",
    "7. How many cameras (and corresponding 2D point locations) do you need to compute the location of $X, Y, Z, W$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92a105d-c61e-4278-922d-1910ad2391a4",
   "metadata": {},
   "source": [
    "#### Structure from motion - notes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
