{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3109b7e-0092-47a3-aca2-288e745731ba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Lecture 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0357b50-2962-423e-85f1-80217ec3d134",
   "metadata": {},
   "source": [
    "#### Announcements\n",
    "\n",
    "* Faculty candidate talks coming up!\n",
    "    * Alli Nilles\n",
    "        * Tuesday 1/30 4pm CF 316 Teaching Demo: Introduction to the Branch-and-Bound Approach\n",
    "    * Brad McCoy (Computational Topology)\n",
    "        * Thursday 2/1 4pm CF 105 Research Talk: An Invitation to Computational Topology\n",
    "        * Friday 2/2 4pm CF 316 Teaching Demo: Dynamic Programming and Edit Distance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d66231d-1f98-4a8a-acf9-11e529056efb",
   "metadata": {},
   "source": [
    "#### Throwback Tuesday: Notes on the Laplacian pyramid down/up weirdness:\n",
    "\n",
    "On the way down, we do:\n",
    "\n",
    "$$L_i = G_i - blur(G_i)$$\n",
    "$$G_{i+1} = sub(blur(G_i))$$\n",
    "\n",
    "On the way back up, we do:\n",
    "$$G_i = up(G_{i+1}) + L_i$$\n",
    "\n",
    "We'd like for these to be inverses; in other words, if we rearrange the \"up\" to solve for $L_i$, they should be equal:\n",
    "\n",
    "$$\\textrm{(downward)\\hspace{2em}   } G_i - up(G_{i+1}) \\stackrel{?}{=} G_i - blur(G_i) \\textrm{\\hspace{2em}(upward)}$$\n",
    "Cancel some terms:\n",
    "$$\\textrm{(downward)\\hspace{2em}   } up(G_{i+1}) \\stackrel{?}{=} blur(G_i) \\textrm{\\hspace{2em}(upward)}$$\n",
    "\n",
    "But if we plug in the downward definition of $G_{i+1}$ on the left, we get:\n",
    "$$\\textrm{(downward)\\hspace{2em}   } up(sub(blur(G_i))) \\stackrel{?}{=} blur(G_i) \\textrm{\\hspace{2em}(upward)}$$\n",
    "\n",
    "This would be true if $up$ and $sub$ were perfect inverses on a blurred image, but they're not.\n",
    "\n",
    "We can fix this by changing the downward-direction rule; instead of \n",
    "$$L_i = G_i - blur(G_i)$$\n",
    "we will replace $blur(G_i)$ with the upsampled version of $G_{i+1}$ that we'll actually have on the way back up:\n",
    "$$L_i = G_i - up(G_{i+1})$$\n",
    "$$L_i = G_i - up(sub(blur(G_i))$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38efd636-c09e-4d1f-a828-33e0fcc75686",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Goals\n",
    "* Analyze the invariances provided (and not provided) by the Harris corner detector\n",
    "* Understand the mathematical framework for (linear) geometric transformations on images (image warping).\n",
    "* Know what is possible with 2D linear transformations (scale, shear, rotation)\n",
    "* Understand the motivation and math behind homogeneous coordinates.\n",
    "* Know what is possible with 2D affine transformations (all of the above, plus translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a295613-e6e3-4f35-b603-27b158385acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boilerplate setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.abspath(\"../src\")\n",
    "if (src_path not in sys.path):\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Library imports\n",
    "import numpy as np\n",
    "import imageio.v3 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage as skim\n",
    "import cv2\n",
    "\n",
    "# codebase imports\n",
    "import util\n",
    "import filtering\n",
    "import features\n",
    "import geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ed4ad7-132d-4906-8a67-fae476b90b39",
   "metadata": {},
   "source": [
    "#### Plan\n",
    "\n",
    "* Harris Invariances\n",
    "* 2D linear tx\n",
    "* Break\n",
    "* Affine tx\n",
    "* MOPS descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d795b83-42fc-467b-a5a1-c9125c68740b",
   "metadata": {},
   "source": [
    "### Good Features:\n",
    "\n",
    "What makes good features?\n",
    "\n",
    "* **Uniqueness**: features **shouldn't** match if they're from different points in the scene. ",
    " ",
    "\n",
    "* **Invariance**: features **should** match if they do come from the same point in the scene.\n",
    "\n",
    "With Harris corners, we achieved **local uniqueness**. For now, we're going to punt on **global uniqueness** until later.\n",
    "\n",
    "Invariance depends on both the feature points selected **and** on how you describe them. Let's look at the detection side first.\n",
    "\n",
    "What do we want to be invariant to? Various things that might change from one image to another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3452bd-a393-4be1-af55-575601f5bb5a",
   "metadata": {},
   "source": [
    "#### Invariance: Easy Mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc58f5d-8af3-4a0b-9017-8cfea7ce23f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=((10, 5)))\n",
    "plt.imshow(imageio.imread(\"../data/L06/trevi_easy.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1792d47-c75f-445e-9fe2-dcb8f3a1aa96",
   "metadata": {},
   "source": [
    "#### Invariance: Hard Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e97b6a0-0752-4803-a903-dcbcede84f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=((10, 5)))\n",
    "plt.imshow(imageio.imread(\"../data/L06/trevi_hard.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7af171-491a-413d-8f2c-8dc256d4314b",
   "metadata": {},
   "source": [
    "#### Invariance: Mars Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f7272-9eb0-407f-b452-27377c0448e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=((10, 5)))\n",
    "plt.imshow(imageio.imread(\"../data/L06/mars2.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3af11e-a304-4dd8-99e6-3bded6a557a4",
   "metadata": {},
   "source": [
    "Things we might want to be invariant to (an aspirational list):\n",
    "* Geometric transformations\n",
    "    * Translation\n",
    "    * Scale\n",
    "    * Rotation\n",
    "    * Viewpoint change / geometry change\n",
    "* Photometric transformations\n",
    "    * Color/intensity shift/scale\n",
    "    * Contrast adjustment\n",
    " \n",
    "Others that aren't clearly one of the above: motion blur, noise, occlusion, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e238cc2-8c86-4053-960d-a1f9efacf003",
   "metadata": {},
   "source": [
    "##### Homework Problem 1\n",
    "Comment on whether (or the extent to which) the Harris corner detector is robust to each of the following transformations. In other words, which of these will not affect which points will be found as corners by the Harris detector? If the detector is almost but not quite completely robust to a given change, comment on this. Assume edge effects and intensity clipping are not an issue.\n",
    "1. Intensity shift: $I(x, y)' = I(x, y) + 20$\n",
    "2. Intensity scale: $I(x, y)' = 1.2 I(x, y)$\n",
    "3. Scaling: $I(x, y)' = I(0.5x, 0.5y)$\n",
    "4. Translation $I(x, y)' = I(x - 10, y)$\n",
    "5. Rotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad55553-dccf-4be9-9764-6f46c8c729b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b71377d-2c64-4397-87d2-e98832f981ad",
   "metadata": {},
   "source": [
    "### A Mathematical Digression: Geometric Transformations\n",
    "\n",
    "Notice that I ran out of math in the last subproblem above - how do I write this down? We've reached the point where it becomes nicer to talk about geometric transformations using the language of linear algebra.\n",
    "\n",
    "Whiteboard linear algebra review:\n",
    "* A 2x2 matrix is a mapping from points to points\n",
    "* You can interpret it two ways:\n",
    "    * Where does it send a point?\n",
    "    * What coordinate system does it translate points *from*? This is the change-of-basis vew.\n",
    "* Rotation matrices: to rotate $\\theta$ counter-clockwise, the matrix is:\n",
    "  $$\n",
    "  \\begin{bmatrix}\n",
    "  \\cos \\theta & \\sin \\theta \\\\\n",
    "  -\\sin \\theta & \\cos \\theta \\\\\n",
    "  \\end{bmatrix}\n",
    "  $$\n",
    "* Transformations can compose (they are linear!). If you let M = AB and apply it to Mx, then B happens first, then A!\n",
    "    * Sometimes this matters, since matrix multiplication doesn't commute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc867b5-23a6-4b4f-a0e5-e5acb6e85338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geometry\n",
    "ferris = imageio.imread(\"../data/L06/tx.png\").astype(np.float32) / 255\n",
    "ferris = skim.transform.rescale(ferris[:,:,:3], (0.5, 0.5, 1))\n",
    "\n",
    "H, W = ferris.shape[:2]\n",
    "util.imshow_truesize(ferris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbba6a76-9a28-4811-8899-2c88e289fd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_ferris(tx, **kwargs):\n",
    "    fw = geometry.warp(ferris, M, **kwargs)\n",
    "    util.imshow_truesize(fw)\n",
    "    # plt.gca().set_axis_off()\n",
    "\n",
    "M = np.array([\n",
    "    [1.0, 0.0],\n",
    "    [0.0, 1.0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "warp_ferris(M, dsize=(W, H))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271d5a3c-8dd7-4688-b2c2-a20782853fe4",
   "metadata": {},
   "source": [
    "##### Homework Problems 2-5\n",
    "\n",
    "**Important note: the coordinate system conventions here differ from the homework! Here, (0, 0) is at the top left and y points down In the HW visualizations, the origin is at the bottom left and y points up.**\n",
    "\n",
    "2. Scale uniformly by a factor of 1.3:\n",
    "\n",
    "   ![](../data/L06/tx1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c22063a-554c-4759-9e7a-b59d4f3209e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([\n",
    "    [1.0, 0.0],\n",
    "    [0.0, 1.0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "warp_ferris(M, dsize=(int(W*1.3), int(H*1.3)), bottom_left_origin=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0310b4d8-1f5f-40a7-8cda-d5f78e25ec30",
   "metadata": {},
   "source": [
    "3. Scale by a factor of 2 in only the $x$ direction:\n",
    "\n",
    "    ![](../data/L06/tx2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8074194-fa25-48bf-8ce6-df70e33be9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([\n",
    "    [1.0, 0.0],\n",
    "    [0.0, 1.0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "warp_ferris(M, dsize=(W*2, H))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5492de0-af5f-417e-b583-3c22c86bc6df",
   "metadata": {},
   "source": [
    "4. Skew or *shear* the image so the top row of pixels is shifted over by 1/4 of the image's height.\n",
    "\n",
    "    ![](../data/L06/tx3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a3c56-2706-471c-bdea-724bc4b98037",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([\n",
    "    [1.0, 0.0],\n",
    "    [0.0, 1.0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "warp_ferris(M, dsize=(int(W*1.25), H))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e413dd-c8b3-4780-9af6-e1fb37c5e17d",
   "metadata": {},
   "source": [
    "5. Rotate the image counter-clockwise by 30 degrees:\n",
    "\n",
    "    ![](../data/L06/tx4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e72f15f-ee4d-4bf7-bff6-ffa6ec4f5c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "rad30 = np.radians(30)\n",
    "\n",
    "M = np.array([\n",
    "    [1.0, 0.0],\n",
    "    [0.0, 1.0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "warp_ferris(M, dsize=(int(W), int(H*1.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f94f9bc-01b9-42db-9457-525b01d324f6",
   "metadata": {},
   "source": [
    "6. Translate the image up and right by (say) 40 pixels:\n",
    "![](../data/L06/tx5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a1b976-a7b6-4e73-94fb-f54fa2111020",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa65a53-ed5c-4a92-a5aa-c55edc651385",
   "metadata": {},
   "source": [
    "Scott is the worst. This one's impossible!\n",
    "\n",
    "Proof: no matrix can move (0, 0) to anywhere but (0, 0).\n",
    "\n",
    "Hack: add a column! This is the same hack as the bias trick from ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3110a5fc-0c2f-47f5-99bd-5dc896b96129",
   "metadata": {},
   "source": [
    "Whiteboard: Affine transformations\n",
    "\n",
    "\n",
    "Just like 2x2 linear transformations can be seen as a change of basis, affine can be seen as a **change of frame**, where the origin may also \n",
    "move. This will come back to haunt us later!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a9690-9d17-422f-af51-5962ca8f7bb1",
   "metadata": {},
   "source": [
    "### Back to the Features!\n",
    "\n",
    "For our feature descriptors, we agreed that a patch of pixels is more unique than a single pixel value. Let's start there, and add invariances to the following:\n",
    "\n",
    "* Rotation\n",
    "* (some) intensity shifts and scales ($I' = aI + b$, sort of)\n",
    "* Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4936bb27-fe38-47d7-9e37-cb698ae16161",
   "metadata": {},
   "source": [
    "#### The MOPS Feature descriptor\n",
    "Multi-scale oriented patches\n",
    "\n",
    "Rotation: rotate the gradient direction to angle 0 (horizontal, presumably)\n",
    "Intensity: subtract mean and divide by standard deviation\n",
    "Scale: run it on a Gaussian pyramid\n",
    "\n",
    "But how do we even extract a patch in the first place?\n",
    "\n",
    "(**whiteboard**: patch extraction transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5418a817-5bf1-4bcc-94df-95362c87530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import features\n",
    "\n",
    "h = imageio.imread(\"../data/harris_crop.jpg\")\n",
    "h = skim.color.rgb2gray(h.astype(np.float32) / 255)\n",
    "\n",
    "corner_mask = features.harris_corners(h, 0.1)\n",
    "plt.imshow(corner_mask)\n",
    "features.get_harris_points(corner_mask).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3930f76-f77e-4e60-a14c-eee8e2dbb7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.imshow_gray(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310ba151-f136-48a3-9e1e-2794ee36ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x = [59,  32]\n",
    "util.imshow_gray(features.extract_MOPS(h, (y, x))) \n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
