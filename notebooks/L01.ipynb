{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1650eb1-d503-4096-aea2-dec7faa2d903",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Lecture 1\n",
    "\n",
    "#### Goals\n",
    "\n",
    "* Know about a sampling of computer vision applications and understand the notion of vision tasks ranging from \"low level\" to \"high level\"\n",
    "* Appreciate why computer vision is hard\n",
    "* Know how images are formed under a simple pinhole camera model\n",
    "* Understand how images are represented:\n",
    "  * On a computer\n",
    "  * In math\n",
    "* Know how to represent color using different color spaces including RGB, HSV, and Lab\n",
    "* Be able to write down mathematical image transformations that perform\n",
    "  simple photometric or geometric manipulations of images functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6385b-3914-4027-875a-14e9549e5b43",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Lesson Plan\n",
    "\n",
    "Quick introductions and day-1 logistics; name cards.\n",
    "\n",
    "Some logistics / introductory remarks:\n",
    " \n",
    "  \n",
    "\n",
    "What is computer vision? \n",
    "\n",
    "Why is it hard?\n",
    "\n",
    "(**break** here?)\n",
    "\n",
    "How are images formed?\n",
    "\n",
    "(or **break** here)\n",
    "\n",
    "How are images represented?\n",
    "\n",
    "What can we *do* to images?\n",
    "* Photometric transformations\n",
    "* Geometric transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6d3ef7-de4b-45ff-bda3-b4d9b6f55ce5",
   "metadata": {},
   "source": [
    "#### Logistics / Introductory Remarks\n",
    " * About me\n",
    " * About you\n",
    "     * Name cards\n",
    "     * Canvas survey out, due tomorrow night\n",
    "     * Informal poll questions:\n",
    "         * Taken ML here?\n",
    "         * Worked with numpy before?\n",
    "         * Got up before 7 this morning?\n",
    " * Course webpage / syllabus: https://facultyweb.cs.wwu.edu/~wehrwes/courses/csci476_24w/. Also available on Canvas Syllabus page.\n",
    "    * **For Thursday:** read the syllabus and bring questions Thursday.\n",
    " * Format remarks\n",
    "     * 2-hour classes\n",
    "     * Jupyterlab + whiteboard\n",
    "       * Lecture are in a public github repo: https://github.com/csci476-24w/476-lectures\n",
    "     * 476 (undergrad) and 576 (grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81204a29-3bf9-4e29-b4ab-0b08b7d92591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.abspath(\"../src\")\n",
    "if (src_path not in sys.path):\n",
    "    sys.path.insert(0, src_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437ba852-8248-44d7-b28a-a9baa49d67fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import numpy as np\n",
    "import imageio.v3 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage as skim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2b4338-42dc-4169-a497-bf5d9a4678b1",
   "metadata": {},
   "source": [
    "### What comes to mind when you hear computer vision?\n",
    "Brainstorm:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3a2925-96c1-4d17-b526-1cde8d091a67",
   "metadata": {},
   "source": [
    "### Some classic computer vision problems:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6b2847-eb29-4a24-bc7c-7ddae64cd641",
   "metadata": {},
   "source": [
    "### Why are these hard problems?\n",
    "\n",
    "* We humans have excellent visual systems built-in, and it's easy to take a lot of our capabilities for granted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ab6def-3ebd-49ca-93a5-3d7e7055e8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "funny = imageio.imread(\"../data/obamafunny.jpg\")\n",
    "plt.imshow(funny)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f52dc0d-4fba-4580-ac7b-a669db85362e",
   "metadata": {},
   "source": [
    "Source: [The state of Computer Vision and AI: we are really, really far away (2012)](http://karpathy.github.io/2012/10/22/state-of-computer-vision/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42603de1-874d-4fcb-b1e1-2eb565fd34ba",
   "metadata": {},
   "source": [
    "**Question to ponder**: are we still really, really far? Can GPT-4V explain why the image is funny?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4bd78a-982a-45fa-b846-86d0dc69a1e8",
   "metadata": {},
   "source": [
    "### Our starting point:\n",
    "Zoom in on the top left corner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ff019f-bca2-452f-9008-81b14000a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(funny[:12, :12, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7133de84-ad52-4ba8-96bb-871d418024a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "funny[:12, :12, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d11fbf-545d-421b-8969-0c5d8e3f1f2e",
   "metadata": {},
   "source": [
    "### Reasons vision is hard:\n",
    "\n",
    "* Definitions - what is a cat even? (google image search for cat)\n",
    "* Ambiguities - 3D to 2D projection, color vs lighting vs depth discontinuity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cf0f13-43e0-41b9-9cf0-852b0069487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(funny[300:400, 500:550])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf9f5ad-cb83-4327-a0b6-fea8af8c4c89",
   "metadata": {},
   "source": [
    "* Scale\n",
    "    * images are big (MB)\n",
    "    * videos are bigger (GB)\n",
    "    * representative sets of images are even bigger than that (?? up to millions or billions of images)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681f9d42-006a-4580-bde3-c1c4cdfa14e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show size of funny"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f30aa30-72ba-40ae-bc28-dd49e129e8a1",
   "metadata": {},
   "source": [
    "##### **HW problem 1:**\n",
    "Rank the following computer vision tasks from \"low-level\" to \"high-level\". There is not necessarily a single right answer, but there are many orderings we should all be able to agree on.\n",
    "\n",
    "1. Smoothing out graininess in an image without blurring the edges of objects\n",
    "2. For each pixel in a video frame, estimate the location of that pixel's content in the following frame (i.e., estimate per-pixel motion vectors, AKA optical flow)\n",
    "3. Labeling all the cats in a photo\n",
    "4. Generating an English language explanation of why an image is funny\n",
    "5. Brightening an image\n",
    "6. Reconstructing the 3D geometry of an object given photos from multiple perspectives\n",
    "7. Segmenting the foreground to create a background blur effect for videoconferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c49301-f3ec-4211-8589-46f1b3b89e7d",
   "metadata": {},
   "source": [
    "# Break?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45295ead-a1d7-470e-9e4a-015e29341cd1",
   "metadata": {},
   "source": [
    "### Image Formation\n",
    "How do images come into existence?\n",
    "\n",
    "Whiteboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76394258-26e1-4dce-916d-4cfc17d250a3",
   "metadata": {},
   "source": [
    "##### **HW problem 2:**\n",
    "\n",
    "A (physical) pinhole camera is simply a box with a hole in it. Describe how the image would change if you made the distance from the pinhole to the back of the box longer or shorter. Assume the other box dimensions stay the same.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410bf524-2aef-484c-8b51-2c81440ec18d",
   "metadata": {},
   "source": [
    "#### What is color?\n",
    "Color theory is surprisingly deep. We'll just scratch the surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d455aaea-35c9-4e81-aeb2-1750d6204963",
   "metadata": {},
   "outputs": [],
   "source": [
    "beans = imageio.imread(\"../data/beans.jpg\")\n",
    "beans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e97c1e-5eaf-4fd9-a5c0-c19636b3b5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at a single pixel of beans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3430e9d3-44a9-4588-b2b1-446d7db746fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# play with different rgb values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2476ded-bf36-484b-8d86-8689e1a397fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.zeros((1,1,3))\n",
    "#c[:] = []\n",
    "plt.imshow(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288a590a-3acf-42e3-a01a-8c614248e558",
   "metadata": {},
   "source": [
    "#### Why RGB?\n",
    "![](https://askabiologist.asu.edu/sites/default/files/resources/articles/seecolor/Light-though-eye-big.png)\n",
    "\n",
    "![](https://askabiologist.asu.edu/sites/default/files/cones_graph.gif)\n",
    "\n",
    "Source: [ASU](https://askabiologist.asu.edu/rods-and-cones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72adb74-f9dc-4b07-841c-9b820961ac1d",
   "metadata": {},
   "source": [
    "##### RGB: Not the only game in town\n",
    "\n",
    "* You can think of RGB color as a cube: [https://www.infinityinsight.com/product.php?id=91](https://www.infinityinsight.com/product.php?id=91)\n",
    "* Pros: display (and vaguely human-eye) native, intuitive-ish\n",
    "\n",
    "A couple other interesting color spaces:\n",
    "##### Hue-Saturation-Lightness (HSL):\n",
    "  * Pros: intuitive control for color picking\n",
    "    \n",
    "  ![](http://www.ece.northwestern.edu/local-apps/matlabhelp/toolbox/images/hsvcone.gif)\n",
    "\n",
    "##### CIE L\\*a\\*b\\*\n",
    "  * Pros:\n",
    "      * the L\\* channel is the luminance, or what the image should look like in \"black and white\"\n",
    "      * (mostly) perceptually uniform\n",
    "  * Cons: a\\* and b\\* give unintuitive control over color\n",
    "     \n",
    "  ![](https://www.xrite.com/-/media/modules/weblog/blog/lab-color-space/lab-color-space.png?h=622&w=600&la=en&hash=53A76941BAB3015346FAB3689739E967843CF8EA)\n",
    "\n",
    "Interactive color picker with many color spaces: [https://colorizer.org/](https://colorizer.org/)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c083ec-b96f-4657-a2d8-e9d9c19cc0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(skim.color.rgb2gray(funny), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11960345-0cde-412b-9f7e-50231ecd7536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# play with skim.color.rgb2hsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18034fd3-853b-486d-8814-5070da35538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# play with skim.color.rgb2lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f73b97c-ebd1-4f22-8665-8a98727acbfa",
   "metadata": {},
   "source": [
    "### Image representation:\n",
    "* Computationally: `ndarray` of size `(height, width, 3)`\n",
    "* Mathematically: a function mapping **position** to **intensity** (or color)\n",
    "    * Grayscale image (one intensity value per pixel): $f: \\mathbb{R}^2 \\Rightarrow \\mathbb{R}$\n",
    "    * Color image (three intensity values per pixel): $f: \\mathbb{R}^2 \\Rightarrow \\mathbb{R^3}$\n",
    " \n",
    "    * A couple points of awkwardness when comparing this to an `ndarray`:\n",
    "      * What happens outside the image boundaries?\n",
    "      * What is the image's intensity value in between integer pixel indices?\n",
    "      * What range of intensity values are mapped onto distinguishable colors on a real display?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb6a6e9-8843-4bef-8061-aa20a29e5385",
   "metadata": {},
   "outputs": [],
   "source": [
    "beans.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0865cf3-01bb-499d-9c2b-36143dfba878",
   "metadata": {},
   "outputs": [],
   "source": [
    "beans.min(), beans.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10d683e-b093-45f9-8d90-aa8158202505",
   "metadata": {},
   "source": [
    "**Important convention:** most standard images (e.g., jpg, png, etc) are stored with 8-bit (1-byte) values for R, G, and B.\n",
    "If we want to do math (or anything!) to an image, we will get quantization error. \n",
    "\n",
    "To avoid this, we always convert to floating-point values after loading. \n",
    "\n",
    "The standard convention for the valid (displayable) **range** of floating-point values is 0 (darkest) to 1 (lightest).\n",
    "\n",
    "For this reason, I wrote a little utility function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8818b810-e029-4020-b4ad-752c5f7530af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codebase imports\n",
    "# nb: the modification to sys.path at the top of the notebook makes these imports from ../src/ work\n",
    "import util\n",
    "import filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3944064a-037e-4207-8c1f-1a3b94ab7db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "beans = util.byte2float(beans)\n",
    "beans.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d68f28-719c-436a-a27b-90a63bdb5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "beans.min(), beans.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2065aa66-5ba8-401a-b675-4e04a7dabee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib obeys these dtype/range conventions:\n",
    "# if it sees bytes, it assumes 0-255\n",
    "# if it sees floats, its assumes 0-1 range\n",
    "plt.imshow(beans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d718bd5-8586-487d-9dd5-a107d69549e7",
   "metadata": {},
   "source": [
    "### What can we *do* to images?\n",
    "\n",
    "One category: **Photometric transformations** - messing with the intensity values.\n",
    "\n",
    "Suppose $g(x, y) = f(x, y) + .2$\n",
    "\n",
    "or in other words,\n",
    "`g = beans + 0.2`\n",
    "\n",
    "How will $g$ compare to $f$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6769b3b8-4fbd-42fb-9a1c-00d3e144aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = beans + 0.2\n",
    "plt.imshow(g.clip(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bffcf4-6ff8-4f83-a79b-810e6de24709",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "##### Brightness\n",
    "\n",
    "$$ g(x, y) = s * f(x, y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c856dd5a-497f-4a75-9f21-a970faf2d9a7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# implement filtering.brightness\n",
    "g = filtering.brightness(beans, 1.3)\n",
    "plt.imshow(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec7de66-23f3-4218-bf0d-af4319a30c4a",
   "metadata": {},
   "source": [
    "##### Thresholding\n",
    "$$\n",
    "h(x, y) = \n",
    "\\begin{cases}\n",
    "0 \\textrm{ if } f(x, y) < t\\\\\n",
    "1 \\textrm{ if } f(x, y) \\ge t\\\\\n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a1a3a9-4665-4f65-aadc-6754e2c75996",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "beans_gray = skim.color.rgb2gray(beans)\n",
    "\n",
    "# implement filtering.threshold\n",
    "g = filtering.threshold(beans_gray, thresh)\n",
    "plt.imshow(g, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9430ed-f644-4cc8-b4cf-86cd5f809ba5",
   "metadata": {},
   "source": [
    "##### **Homework Problems 5-6:**\n",
    "5. Suppose you want to make an RGB color image stored in an array `a` more saturated, without allowing any pixel values to go outside the range from 0 to 1. Write pseudocode (or python code) to implement this.\n",
    "6. Given a grayscale image $f(x, y)$, how could you increase the *contrast*? In other words, how could you make the bright stuff brighter and dark stuff darker? Give your answer mathematically (not as code), and as above, your approach should not allow values to go outside their original range from 0 to 1; ideally you'll also avoid the need to clamp. *Hint*: try playing around with plotting some different functions on the input range $[0,1]$ to see if you can find one that does what we want. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9abb57c-8643-4e3e-920e-3f64637a4c20",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0f203a3-460b-4a29-a105-4e1f50db7c5c",
   "metadata": {},
   "source": [
    "Another category of image transformations: **geometric transformations** - messing with the domain of the function.\n",
    "\n",
    "Example: $g(x, y) = f(-x, y)$\n",
    "\n",
    "What would this look like?\n",
    "\n",
    "And how would we write it in code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce122180-a595-4ea2-a31e-5150bb905949",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(beans) # perform the above transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9490f42f-471b-4a80-a5d4-be7b6ba0cc2b",
   "metadata": {},
   "source": [
    "##### **Homework Problems 6-7**:\n",
    "6. In terms of an input image $f(x, y)$, write a mathematical expression for a new image $g$ that is shifted four pixels to the left.\n",
    "7. In terms of an input image $f(x, y)$, write a mathematical expression for a new image $g$ that is twice as big (i.e., larger by a factor of two in both $x$ and $y$)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
