{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3109b7e-0092-47a3-aca2-288e745731ba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Lecture 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0357b50-2962-423e-85f1-80217ec3d134",
   "metadata": {},
   "source": [
    "#### Announcements\n",
    "\n",
    "* I made a Discord server for discussion and Q&A. Link on Canvas, please use your real name as your server nickname. I'll try to respond to questions in q-and-a when possible.\n",
    "* Feedback for P01 and P02 came back yesterday. I added a few notes on logistics to the syllabus, just so they're written down somewhere:\n",
    "    * The problems for each lecture will be posted in the [Schedule](#schedule) table by the start of each class. \n",
    "    * Please typset your answers and submit to Canvas in PDF format by Sunday night of the week they are assigned.\n",
    "    * Since these are \"ungraded\", the individual Canvas assignments will be scored out of 0; I will assign a 0/0 and provide feedback to any submissions.\n",
    "    * If you wish to submit or or resubmit anytime after 7am Monday morning after the deadline, please submit via Canvas then send me an email to let me know that you've done so. I will give timely feedback on late and re-submissions on a best-effort basis.\n",
    " \n",
    "* Project 1 is out today. We'll talk about it a bit in class on Thursday.\n",
    "* 476-lectures repo - rather than branching nonsense, I'll just commit `L??_476.ipynb` and `L??_576.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38efd636-c09e-4d1f-a828-33e0fcc75686",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Goals\n",
    "* Know how to compute image derivatives using convolution filters\n",
    "* Understand how to derive and apply the the Sobel edge detection filter\n",
    "* Have an intuitive understanding of spatial frequency in images\n",
    "* Know the meaning and construction of \"low pass\" and \"high pass\" filters\n",
    "* Know how to make images smaller:\n",
    "  * The naive way via subsampling (and why this is bad)\n",
    "  * The principled way by downsampling with prefiltering (and why this is better)\n",
    "* Know how to make images bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a295613-e6e3-4f35-b603-27b158385acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boilerplate setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.abspath(\"../src\")\n",
    "if (src_path not in sys.path):\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Library imports\n",
    "import numpy as np\n",
    "import imageio.v3 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage as skim\n",
    "import cv2\n",
    "\n",
    "# codebase imports\n",
    "import util\n",
    "import filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c488e742-09b7-4454-9b18-59e69022fed3",
   "metadata": {},
   "source": [
    "#### Differentiating Images\n",
    "\n",
    "Images are functions; differentiation is an operator. What does it mean?\n",
    "\n",
    "Since they're functions of two variables, a single-valued output needs to be a partial derivative:\n",
    "* Horizontal ($x$) derivative: $\\frac{\\partial}{\\partial x}  f(x, y)$\n",
    "* Vertical ($y$) derivative: $\\frac{\\partial}{\\partial y}  f(x, y)$\n",
    "\n",
    "We have discrete (i.e., sampled) images, so we need to approximate this with finite differences. Let's design a convolution kernel that accomplishes this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae56d0b8-2483-4b01-9541-7eec1d248409",
   "metadata": {},
   "source": [
    "Whiteboard: calculus reminder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baa11f6-4349-46ea-9ec1-5fac511f0e17",
   "metadata": {},
   "source": [
    "##### Homework Problem 1\n",
    "\n",
    "Consider the following two candidate horizontal derivative filters.\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "  1 & -1 & 0\\\\\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "  1 & 0 & -1\\\\\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "  1. Why is the negative number to the right of the positive one?\n",
    "  2. If we wanted to accurately calculate the slope with correct scale, how would we need to modify the above kernels?\n",
    "  3. What are the relative merits of each of these filters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59449a2-c06c-4587-8fb3-1696f59bce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes = imageio.imread(\"../data/bikesgray.jpg\").astype(np.float32) / 255.0\n",
    "bikes = skim.transform.rescale(bikes, 0.5, anti_aliasing=True)\n",
    "bikes = bikes + np.random.randn(*bikes.shape) * 0.05\n",
    "\n",
    "util.imshow_gray(bikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8813bee2-4801-408a-b449-bfa503d076c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = np.array([-1, 0, 1]).reshape((1, 3)) / 2\n",
    "dy = dx.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aeb88e-f10e-4c32-9a5b-97e186c929c2",
   "metadata": {},
   "source": [
    "**Look at `filtering.py`**\n",
    "* I tweaked our `filter` function to handle non-square kernels.\n",
    "* I added a `convolve` that just flips the kernel then runs `filter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ff3f3c-21ee-4f6f-8a52-5cf36ea1f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bx = filtering.filter(bikes, dx)\n",
    "by = filtering.filter(bikes, dy)\n",
    "\n",
    "util.imshow_gray(np.hstack([bx, by]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e679c-483f-4e0f-901a-0a95967ccb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.imshow_gray(np.hstack([bx[30:80, :50], by[30:80, :50]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bb5221-c5c0-465d-a204-1bbb5d7d4aac",
   "metadata": {},
   "source": [
    "Let's look at the intensities along a single scanline. This one is a vertical scanline that crosses the brick pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571dcc54-c2de-49f2-91cb-e887a33ff8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bikes[:,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a450c3-0d65-4995-8a52-1bdf1eb9d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(by[:,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaff1c4-df55-49cf-8fce-3af54d99a304",
   "metadata": {},
   "source": [
    "This motivates an idea: blur the noise so that the real edges stick out!\n",
    "\n",
    "Why use 2 filters when you could use just 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7af8640-2862-4f0b-b1e6-093193b05da5",
   "metadata": {},
   "source": [
    "##### Homework Problem 2\n",
    "\n",
    "Compute the following convolution, which results in a new filter kernel, and describe the effect of this new kernel in words.\n",
    "   $$\n",
    "   \\begin{bmatrix}\n",
    "     1 & 2 & 1\\\\\n",
    "     2 & 4 & 2\\\\\n",
    "     1 & 2 & 1\n",
    "   \\end{bmatrix} *\n",
    "   \\begin{bmatrix}\n",
    "     0 & 0 & 0\\\\\n",
    "     1 & 0 & -1\\\\\n",
    "     0 & 0 & 0\n",
    "   \\end{bmatrix} = \n",
    "   \\begin{bmatrix}\n",
    "     \\  & \\ & \\ \\\\\n",
    "     \\ & \\ & \\ \\\\\n",
    "     \\hspace{1em} & \\hspace{1em} & \\hspace{1em}\n",
    "   \\end{bmatrix}\n",
    "   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a455b715-c825-4e27-b43c-8e9bca5b4f57",
   "metadata": {},
   "source": [
    "Let's check our work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58c0bbd-99be-46c7-a4a1-e988160d7ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = np.array([\n",
    "    [1, 2, 1],\n",
    "    [2, 4, 2],\n",
    "    [1, 2, 1]], dtype=np.float32)\n",
    "\n",
    "dx = np.array([\n",
    "    [0, 0,  0],\n",
    "    [1, 0, -1],\n",
    "    [0, 0,  0]], dtype=np.float32)\n",
    "\n",
    "# check our answer\n",
    "xsobel = filtering.convolve(blur, dx)\n",
    "ysobel = xsobel.T\n",
    "xsobel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38394b6-8f57-4fa0-a388-54af30261abc",
   "metadata": {},
   "source": [
    "For whatever reason, this is more often written scaled down by 1/2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7d3be8-6b49-4444-a8c4-5673fa28cb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "xsobel /= 2\n",
    "ysobel = xsobel.T\n",
    "xsobel, ysobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfcb5ce-f6c6-4595-8073-d83d49f7e04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bx = filtering.convolve(bikes, xsobel)\n",
    "by = filtering.convolve(bikes, ysobel)\n",
    "\n",
    "util.imshow_gray(np.hstack([bx, by]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bdfe3c-e198-4909-a92d-5b6314a5b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(by[:,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab244076-f773-4e96-a310-db0e81e295b6",
   "metadata": {},
   "source": [
    "### From sobel to edge detection\n",
    "\n",
    "Direction-independent edge detector?\n",
    "First pass: gradient magnitude\n",
    "\n",
    "$$ \\Delta f =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial}{\\partial x}  f \\\\\n",
    "\\frac{\\partial}{\\partial y}  f\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Edge strength: gradient magnitude $||\\Delta f||$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a042f14a-71f9-409d-acf2-f0d7edf15b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.sqrt(bx ** 2 + by**2), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ab5021-7948-487d-858b-c6718d9e338b",
   "metadata": {},
   "source": [
    "This is useful enough that I wrote `filtering.grad_mag` to make it simple to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64827068-cf49-4008-a66c-7c85ed09fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.imshow_gray(filtering.grad_mag(bikes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec16544-4767-4b89-9a67-5179ab14226c",
   "metadata": {},
   "source": [
    "Classical fancier method: [**Canny Edge Detector**](https://en.wikipedia.org/wiki/Canny_edge_detector#Walkthrough_of_the_algorithm)\n",
    "* Convert to grayscale\n",
    "* Blur with 5x5 $\\sigma=1.4$ Gaussian\n",
    "* Calculate gradient magnitude\n",
    "* Apply non-maximum suppression\n",
    "* Threshold with 2 cutoffs for strong edges, weak edges, and non-edges\n",
    "* Preserve only weak edges that connect to strong edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a043bf41-4050-4424-8d33-69eb365f64ee",
   "metadata": {},
   "source": [
    "## Spatial Frequency\n",
    "\n",
    "Whiteboard - intuition (only) for the Fourier decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b1ddd1-543b-4c6f-8c48-626d8fd89020",
   "metadata": {},
   "source": [
    "#### Introducing: the Frequencyometer(TM)\n",
    "A very imprecise way of talking about what spatial frequencies are present in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb0c24d-ff46-4acd-9025-5142f789d3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "beans = imageio.imread(\"../data/beans.jpg\").astype(np.float32) / 255.0\n",
    "bg = skim.color.rgb2gray(beans) # grayscale beans\n",
    "\n",
    "plt.imshow(beans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd0ccf4-c628-42a6-896a-1dd5ffdebff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(beans[400:500, 100:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2134792d-cf8b-4de6-b3a3-f416c03db7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(beans[20:120, 500:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00df5edf-38eb-478f-b48d-ee6d4d2bda84",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(beans[420:480, 550:600])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a201a8c6-1640-4978-8694-7ed6abc18420",
   "metadata": {},
   "source": [
    "#### Definitions: \"Low-Pass\" and \"High-Pass\" filters\n",
    "\n",
    "Low-pass: allows low frequencies to pass through unaffected, i.e., attenuates high frequencies.\n",
    "* In other words: blur!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aa26bf-d89b-42b4-b944-f6bd642c15b3",
   "metadata": {},
   "source": [
    "High-pass: allows high frequencies to pass through unaffected, i.e., attenuates low frequencies.\n",
    "* In other words: derivative, (with slight but common terminology abuse) sobel, or  sharpening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fc2f0f-5492-4d5d-b9c7-d5bc6743c2b9",
   "metadata": {},
   "source": [
    "Question that didn't make it onto the homework: in what sense is Sobel not truly a high-pass filter?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402c3316-cf45-472d-81a7-f471653db6e3",
   "metadata": {},
   "source": [
    "##### Homework Problems 3-6\n",
    "\n",
    "(3) Using the language of \"low-\" and \"high-frequency\" image content, explain why sharpening is not the inverse of blurring, and what it accomplishes instead.\n",
    "\n",
    "(4) Consider the original image of beans on the left, and the processed version on the right. Describe what has changed in terms of frequency content.\n",
    "\n",
    "   ![](../data/beans_frequency.jpg)\n",
    "   \n",
    "(5) What's the **maximum** frequency (expressed in full periods per pixel) representable in a 1D image (i.e., a row of pixels)? What does such an image look like?\n",
    "\n",
    "(6) What's the **minimum** frequency representable in a 1D image? What does such an image look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2ec657-81ab-4e88-b7ca-fe1fbf5b1ca8",
   "metadata": {},
   "source": [
    "## Break, if we haven't already taken one!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7f2446-6534-4abd-aeaa-9c7ad8d43134",
   "metadata": {},
   "source": [
    "### Downsampling\n",
    "\n",
    "My image is too big to fit on my screen. For example, suppose beans is 600x600, but I want to display the image in 300x300 pixels. What should I do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08df66bc-dcc0-4284-84ac-74e46708f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg.shape # beans grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c159bc8-5f35-44ce-b0e6-f706e80e69ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.imshow_truesize(bg[::2,::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d74f98-f73b-4546-a01e-d1aa088fdf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bricks = imageio.imread(\"../data/bricks.jpg\").astype(np.float32) / 255.0\n",
    "plt.imshow(bricks[::4,::4,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a51eb9-3ed7-4ea1-bfb5-25f4028f853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checker = np.zeros((1, 16))\n",
    "checker[:, ::2] = 1.0\n",
    "util.imshow_gray(checker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c212a3b4-8de6-415c-8eea-dca4672d8f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(checker[:, ::2], vmin=0, vmax=1, cmap=\"gray\") # force color scale to [0,1] range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b85e35-eb1e-4dd2-ae88-49b06da5c85b",
   "metadata": {},
   "source": [
    "##### Homework Problem 7\n",
    "\n",
    "If you walked far away from the above image until you couldn't distinguish individual pixels, what would it look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8905c382-36be-47db-a8cf-fc3a92026a27",
   "metadata": {},
   "source": [
    "**Whiteboard**: downsampling freqeuncyometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4855549-34d9-41fe-acde-0fbde7ab147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: implement filtering.down_2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6584da2e-ddff-442a-9bf1-cb394f7447bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.imshow_truesize(bg[::4,::4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050af4ca-9739-42a9-9f2e-ecbd58ba4a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: implement down_2x\n",
    "util.imshow_truesize(filtering.down_4x(bg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ff623f-09d5-4a95-96f6-9a173586df3f",
   "metadata": {},
   "source": [
    "### Upsampling\n",
    "\n",
    "My image is too small for my screen. For example, suppose beans is 150x150, but I want to display the image in 600x600 pixels. What should I do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc232213-5c8a-41b9-9b73-53b4bad3df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "beans300 = filtering.down_4x(bg)\n",
    "util.imshow_truesize(beans150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41483a31-3a19-4518-9b6a-32c59bc7c1d5",
   "metadata": {},
   "source": [
    "See naive version preimplemented in `filtering.up_2x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de18e4f-a9a0-47ce-accd-6a724bcb16bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.imshow_truesize(filtering.up_4x(beans150, interp=\"nn\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978c1902-84c7-49cc-a013-6e6e8ea210b7",
   "metadata": {},
   "source": [
    "**Whiteboard:** Filtering view of upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc890945-1eda-4c44-afed-a442cdecf840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: implement reconstruction filtering version in up_2x\n",
    "# - Gaussian reconstruction filter\n",
    "# - Linear reconstruction filter\n",
    "util.imshow_truesize(filtering.up_4x(beans150, interp=\"gaussian\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
